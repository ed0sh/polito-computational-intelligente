{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In collaboration w/ [Giovanni Bordero s313010](https://github.com/Giobordi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:17.981973Z",
     "start_time": "2023-12-19T20:43:17.815534Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, namedtuple\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "WIN_SCORE = 2\n",
    "LOSE_SCORE = -5\n",
    "DRAW_SCORE = -1\n",
    "\n",
    "TRAINING_EPOCHS = 100_000\n",
    "\n",
    "NUM_TEST_GAMES = 10_000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:17.986053Z",
     "start_time": "2023-12-19T20:43:17.983785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])\n",
    "\n",
    "class Player(Enum):\n",
    "    X = 1,\n",
    "    O = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:17.989939Z",
     "start_time": "2023-12-19T20:43:17.986115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.magic = [4, 9, 2,\n",
    "                      3, 5, 7,\n",
    "                      8, 1, 6]\n",
    "        ### player 1 is x and player 2 is o\n",
    "        self.state = State(set(), set())\n",
    "        self.move = 0\n",
    "        self.my_player = Player.X\n",
    "\n",
    "    def sum_magic(self, comb: tuple) -> int:\n",
    "        \"\"\"get the magic sum of the elements in comb\"\"\"\n",
    "        return sum(self.magic[i] for i in comb)\n",
    "\n",
    "    def check_win(self, player: Player) -> bool:\n",
    "        \"\"\"check if the player win the game\"\"\"\n",
    "        if self.move < 5:\n",
    "            return False\n",
    "        if player == Player.X:\n",
    "            return any(self.sum_magic(comb) == 15 for comb in itertools.combinations(self.state.x, 3))\n",
    "        if player == Player.O:\n",
    "            return any(self.sum_magic(comb) == 15 for comb in itertools.combinations(self.state.o, 3))\n",
    "\n",
    "    def check_draw(self) -> bool:\n",
    "        \"\"\"check if the game is a draw\"\"\"\n",
    "        if self.move == 9 and not self.check_win(Player.X) and not self.check_win(Player.O):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def move_done(self, move: int, player: Player) -> None:\n",
    "        \"\"\"apply a move to the game\"\"\"\n",
    "        self.move += 1\n",
    "        if player == Player.X:\n",
    "            self.state.x.add(move)\n",
    "        elif player == Player.O:\n",
    "            self.state.o.add(move)\n",
    "        # self.good_print()\n",
    "\n",
    "    def evaluate_match(self) -> int:\n",
    "        if self.check_win(self.my_player):\n",
    "            return 1\n",
    "        elif self.check_win(Player.O if self.my_player == Player.X else Player.X):\n",
    "            return -1\n",
    "        elif self.check_draw():\n",
    "            return 0\n",
    "\n",
    "    def good_print(self):\n",
    "        \"\"\"print the board of the game in a human-readable format\"\"\"\n",
    "        num = ['0️⃣', '1️⃣', '2️⃣', '3️⃣', '4️⃣', '5️⃣', '6️⃣', '7️⃣', \"8️⃣\"]\n",
    "        counter = 0\n",
    "        for r in range(3):\n",
    "            print('|', end='')\n",
    "            for c in range(3):\n",
    "                val = r * 3 + c\n",
    "                if val in self.state.x:\n",
    "                    print('✖️|', end='')\n",
    "                elif val in self.state.o:\n",
    "                    print('⭕|', end='')\n",
    "                else:\n",
    "                    print(f'{num[counter]}|', end=\"\")\n",
    "                counter += 1\n",
    "            print()\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:17.997016Z",
     "start_time": "2023-12-19T20:43:17.993712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ReinforcedPlayer2:\n",
    "    def __init__(self):\n",
    "        self.Q = defaultdict(float)\n",
    "        self.epsilon = 0.01\n",
    "        self.training_epochs = TRAINING_EPOCHS\n",
    "\n",
    "    def get_Q_value(self, state, action):\n",
    "        tmp = deepcopy(state)\n",
    "        st = (frozenset(tmp.x), frozenset(tmp.o))\n",
    "        if (st, action) not in self.Q:\n",
    "            self.Q[(st, action)] = 0.0\n",
    "        return self.Q[(st, action)]\n",
    "\n",
    "    def update_Q_value(self, state, action: int, reward):\n",
    "        st = (frozenset(state.x), frozenset(state.o))\n",
    "        self.Q[(st, action)] = self.get_Q_value(state, action) + self.epsilon * (\n",
    "                    reward - self.get_Q_value(state, action))\n",
    "\n",
    "    def choose_action(self, state, available_moves):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return random.choice(available_moves)\n",
    "        else:\n",
    "            Q_values = [self.get_Q_value(state, action) for action in available_moves]\n",
    "            max_Q = max(Q_values)\n",
    "            if Q_values.count(max_Q) > 1:\n",
    "                best_moves = [i for i in range(len(available_moves)) if Q_values[i] == max_Q]\n",
    "                i = random.choice(best_moves)\n",
    "            else:\n",
    "                i = Q_values.index(max_Q)\n",
    "            return available_moves[i]\n",
    "\n",
    "    def training(self):\n",
    "        for _ in tqdm(range(self.training_epochs)):\n",
    "            new_game = TicTacToe()\n",
    "            trajectory, reward = self.random_game(new_game)\n",
    "            ## update the Q value for each tuple (state, action) in the trajectory\n",
    "            for state_move in trajectory:\n",
    "                self.update_Q_value(state=state_move[0], action=state_move[1], reward=reward)\n",
    "\n",
    "        save_model(self, f\"EPOCHS_{str(self.training_epochs)}-LOSE_{LOSE_SCORE}-WIN_{WIN_SCORE}-DRAW_{DRAW_SCORE}\")\n",
    "\n",
    "    def random_game(self, game: TicTacToe):\n",
    "        \"\"\"\n",
    "        play a semi random game and return the trajectory of the chosen player (X or O) and the reward.\n",
    "        The reward is 1 if the player win, -1 if the player lose and 0 if it is a draw\n",
    "        \"\"\"\n",
    "        trajectory = list()\n",
    "        available_moves = list(range(0, 9))\n",
    "        ## a random player start\n",
    "        turn = np.random.choice([0, 1])\n",
    "\n",
    "        players = [Player.X, Player.O]\n",
    "        game.my_player = random.choice(players)  ## train the model on random player\n",
    "        # so it is possible to play with both X and O\n",
    "        while len(available_moves) != 0 and not game.check_draw():\n",
    "            turn = 1 - turn\n",
    "\n",
    "            if game.my_player == players[turn]:\n",
    "                move = self.choose_action(game.state, available_moves)\n",
    "                trajectory.append((deepcopy(game.state), move))\n",
    "            else:\n",
    "                move = np.random.choice(available_moves)\n",
    "\n",
    "            available_moves.remove(move)\n",
    "            game.move_done(move, players[turn])\n",
    "\n",
    "            if game.check_win(players[turn]):\n",
    "                if game.my_player == players[turn]:\n",
    "                    return trajectory, WIN_SCORE\n",
    "                else:\n",
    "                    return trajectory, LOSE_SCORE\n",
    "\n",
    "        return trajectory, DRAW_SCORE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:18.007916Z",
     "start_time": "2023-12-19T20:43:18.001025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def save_model(model: ReinforcedPlayer2, text: str = None):\n",
    "    # Serialize the object and write it to a file\n",
    "    with open(f'models/agent-{text}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_model(path: str) -> ReinforcedPlayer2:\n",
    "    # Load the model from a file\n",
    "    with open(path, 'rb') as f:\n",
    "        loaded_instance = pickle.load(f)\n",
    "\n",
    "    return loaded_instance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:43:18.009398Z",
     "start_time": "2023-12-19T20:43:18.004947Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins : 9415, draws: 547, lost: 38\n"
     ]
    }
   ],
   "source": [
    "train = False\n",
    "\n",
    "if train:\n",
    "    rr = ReinforcedPlayer2()\n",
    "    rr.training()\n",
    "    rr2 = load_model('models/agent-EPOCHS_10000000.pkl')\n",
    "else:\n",
    "    rr = load_model('models/agent-EPOCHS_10000000-LOSE_-5-WIN_2-DRAW_-1.pkl')\n",
    "    rr2 = load_model('models/agent-EPOCHS_10000000-LOSE_-5-WIN_2-DRAW_-1.pkl')\n",
    "\n",
    "wins = 0\n",
    "draws = 0\n",
    "for _ in range(NUM_GAMES):\n",
    "    game = TicTacToe()\n",
    "    \n",
    "    turn = np.random.choice([0, 1])\n",
    "    players = [Player.X, Player.O]\n",
    "    rr_player = random.choice(players)\n",
    "    \n",
    "    available_moves = list(range(0, 9))\n",
    "    \n",
    "    while len(available_moves) != 0 and not game.check_draw():\n",
    "        turn = 1 - turn\n",
    "        # game.good_print()\n",
    "        if players[turn] == rr_player:\n",
    "            move = rr.choose_action(game.state, available_moves)\n",
    "        else:\n",
    "            move = random.choice(available_moves)\n",
    "            # move = int(input(\"Enter your move: \"))\n",
    "            # move = rr2.choose_action(game.state, available_moves)\n",
    "\n",
    "        available_moves.remove(move)\n",
    "        game.move_done(move, players[turn])\n",
    "        \n",
    "        if game.check_win(players[turn]):\n",
    "            if players[turn] == rr_player:\n",
    "                wins += 1\n",
    "            break\n",
    "\n",
    "    if game.check_draw():\n",
    "        draws += 1\n",
    "\n",
    "print(f'wins : {wins}, draws: {draws}, lost: {NUM_GAMES - wins - draws}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:44:02.909822Z",
     "start_time": "2023-12-19T20:44:00.595746Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
